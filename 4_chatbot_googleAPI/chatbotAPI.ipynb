{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chineseMovie.yml Training: [####################] 100%\n",
      "myown.yml Training: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "# from chatterbot.trainers import ListTrainer\n",
    "\n",
    "chatbot = ChatBot(\"myBot\")\n",
    "chatbot.set_trainer(ChatterBotCorpusTrainer)\n",
    "\n",
    "# 使用语料库训练它\n",
    "# chatbot.train(\"chatterbot.corpus.english\")\n",
    "# chatbot.train(\"chatterbot.corpus.chinese\")\n",
    "chatbot.train(\"chatterbot.corpus.custom\")\n",
    "# train using list\n",
    "# chatbot.set_trainer(ListTrainer)\n",
    "# chatbot.train(movie_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, subprocess, sys, re, codecs, time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "# with io.open('../../API_KEY.txt') as fp: \n",
    "#     for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "APIKEY='XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is for Google Language Tranlation API\n",
    "service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Natual Language Processing API\n",
    "# nlp_service = build('language', 'v1', developerKey=APIKEY)\n",
    "nlp_service = build('language', 'v1beta2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parm_runtime_env_GCP = True\n",
    "parm_runtime_env_GCP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with io.open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(image_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(image_content).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define control parameters for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# API control parameter for Language Translation API:\n",
    "parm_translation_origin_language = 'zh' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese\n",
    "\n",
    "# API control parameter for 自然语言处理：语义和情感分析\n",
    "parm_nlp_extractDocumentSentiment = True # 情感分析 (Sentiment analysis)\n",
    "parm_nlp_extractEntities = True          # 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "parm_nlp_extractEntitySentiment = False  # Only available in v1beta2. But Chinese language zh is not supported yet.\n",
    "parm_nlp_extractSyntax = True            # 语句的语法分析 (Syntax / Grammar analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize objects in image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 物体名 (General Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LABEL_DETECTION'\n",
    "def ChatbotVS_LABEL_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    \n",
    "    image_analysis_reply = u'\\nDid you send me\\n你给我发的是'\n",
    "    # 'LABEL_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += responses['responses'][0]['labelAnnotations'][0]['description'] + u'？' \\\n",
    "            + '\\n( Possibility 我有' +  str(round(responses['responses'][0]['labelAnnotations'][0]['score'], 3) * 100) + u'%的把握 )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 地标名 (Landmark Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LANDMARK_DETECTION'\n",
    "def ChatbotVS_LANDMARK_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    \n",
    "    image_analysis_reply = u'\\nThis place is\\n这个地方貌似是'\n",
    "    # 'LANDMARK_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += responses['responses'][0]['landmarkAnnotations'][0]['description'] \\\n",
    "            + '\\n( Possibility 可能性' +  str(round(responses['responses'][0]['landmarkAnnotations'][0]['score'], 3) * 100) + '% )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 商标名 (Logo Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LOGO_DETECTION'\n",
    "def ChatbotVS_LOGO_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    \n",
    "    image_analysis_reply = u'\\nThis mark is\\n这个商标好像是'\n",
    "    # 'LOGO_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += responses['responses'][0]['logoAnnotations'][0]['description'] \\\n",
    "            + '\\n( Possibility 可能性' +  str(round(responses['responses'][0]['logoAnnotations'][0]['score'], 3) * 100) + '% )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR: Extract text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'TEXT_DETECTION'\n",
    "def ChatbotVS_TEXT_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\nI found text\\n我找到文字: '\n",
    "    # 'TEXT_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += responses['responses'][0]['textAnnotations'][0]['description']\n",
    "        ##############################################################################################################\n",
    "        #                                        translation of detected text                                        #\n",
    "        ##############################################################################################################\n",
    "        parm_translation_origin_language = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "        # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "        if parm_translation_origin_language != parm_translation_target_language:\n",
    "            inputs=[responses['responses'][0]['textAnnotations'][0]['description']] # TEXT_DETECTION OCR results only\n",
    "            outputs = service.translations().list(source=parm_translation_origin_language, \n",
    "                                                  target=parm_translation_target_language, q=inputs).execute()\n",
    "            image_analysis_reply += outputs['translations'][0]['translatedText'] + '\\n'\n",
    "        ##############################################################################################################\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize human face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'FACE_DETECTION'\n",
    "def ChatbotVS_FACE_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                     \"content\": image_base64\n",
    "#                     'content': str(image_base64.decode(\"utf-8\"))\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\nI found your emotions\\n你们的表情被我发现了:\\n'\n",
    "    # 'FACE_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['faceAnnotations'])):\n",
    "            image_analysis_reply += u'\\nFace No.' + str(i+1) + u'第' + str(i+1) + u'张脸:\\n'\n",
    "            \n",
    "            joy_detect = responses['responses'][0]['faceAnnotations'][i][u'joyLikelihood']\n",
    "            if joy_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Joy 喜悦, ' + u'probability 可能性 :' + joy_detect + '\\n'\n",
    "                \n",
    "            anger_detect = responses['responses'][0]['faceAnnotations'][i][u'angerLikelihood']\n",
    "            if anger_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Anger 愤怒, ' + u'probability 可能性 :' + anger_detect + '\\n'\n",
    "            \n",
    "            sorrow_detect = responses['responses'][0]['faceAnnotations'][i][u'sorrowLikelihood']\n",
    "            if sorrow_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Sorrow 悲伤, ' + u'probability 可能性 :' + sorrow_detect + '\\n'\n",
    "                \n",
    "            surprise_detect = responses['responses'][0]['faceAnnotations'][i][u'surpriseLikelihood']\n",
    "            if surprise_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Surprise 惊奇, ' + u'probability 可能性 :' + surprise_detect + '\\n'\n",
    "                \n",
    "            headwear_detect = responses['responses'][0]['faceAnnotations'][i][u'headwearLikelihood']\n",
    "            if headwear_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Headwear 头饰, ' + u'probability 可能性 :' + headwear_detect + '\\n'\n",
    "                \n",
    "            blurred_detect = responses['responses'][0]['faceAnnotations'][i][u'blurredLikelihood']\n",
    "            if blurred_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'Blurred 模糊, ' + u'probability 可能性 :' + blurred_detect + '\\n'\n",
    "                \n",
    "            underExposed_detect = responses['responses'][0]['faceAnnotations'][i][u'underExposedLikelihood']\n",
    "            if underExposed_detect != 'VERY_UNLIKELY':\n",
    "                image_analysis_reply += u'UnderExposed 欠曝光, ' + u'probability 可能性 :' + underExposed_detect + '\\n'\n",
    "    else:\n",
    "        image_analysis_reply += ''\n",
    "            \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Content Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'SAFE_SEARCH_DETECTION'\n",
    "def ChatbotVS_SAFE_SEARCH_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                     \"content\": image_base64\n",
    "#                     'content': str(image_base64.decode(\"utf-8\"))\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\nI also detected some bad content\\n我还检测到不良内容:\\n'\n",
    "    # 'SAFE_SEARCH_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        \n",
    "        Adult_detect = responses['responses'][0]['safeSearchAnnotation'][u'adult']\n",
    "        if Adult_detect != ('VERY_UNLIKELY' or 'UNLIKELY'):\n",
    "            image_analysis_reply += u'Adult 成人, ' + u'probability 可能性 :' + Adult_detect + '\\n'\n",
    "            \n",
    "        Violence_detect = responses['responses'][0]['safeSearchAnnotation'][u'violence']\n",
    "        if Violence_detect != ('VERY_UNLIKELY' or 'UNLIKELY'):\n",
    "            image_analysis_reply += u'Violence 暴力, ' + u'probability 可能性 :' + Violence_detect + '\\n'\n",
    "            \n",
    "        Spoof_detect = responses['responses'][0]['safeSearchAnnotation'][u'spoof']\n",
    "        if Spoof_detect != ('VERY_UNLIKELY' or 'UNLIKELY'):\n",
    "            image_analysis_reply += u'Spoof 欺骗, ' + u'probability 可能性 :' + Spoof_detect + '\\n'\n",
    "            \n",
    "        Medical_detect = responses['responses'][0]['safeSearchAnnotation'][u'medical']\n",
    "        if Medical_detect != ('VERY_UNLIKELY' or 'UNLIKELY'):\n",
    "            image_analysis_reply += u'Medical 医疗, ' + u'probability 可能性 :' + Medical_detect + '\\n'           \n",
    "    else:\n",
    "        image_analysis_reply += ''\n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text based language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ChatbotVS_TEXT_TRANSLATION(text, origin_language_code, target_language_code):\n",
    "    # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "    if origin_language_code != target_language_code:\n",
    "        outputs = service.translations().list(source=origin_language_code, \n",
    "                                              target=target_language_code, q=text).execute()\n",
    "        outputs_zh = service.translations().list(source=origin_language_code, \n",
    "                                              target='zh', q=text).execute()\n",
    "        \n",
    "        translated_text = u' ---- I translated your text ----\\n ---- 亲，我帮你翻译了一下 ---- \\n\\n'\n",
    "        translated_text += u'( English Text 英文译文: )\\n'\n",
    "        translated_text += outputs['translations'][0]['translatedText'] + '\\n'# + '----- End Translation -----\\n'\n",
    "        translated_text += u'( Chinese Text 中文译文: )\\n'\n",
    "        translated_text += outputs_zh['translations'][0]['translatedText'] + '\\n'\n",
    "    else:\n",
    "        translated_text = text\n",
    "        \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Speech API\n",
    "def ChatbotVS_nlp(text, extractDocumentSentiment, extractEntities, extractEntitySentiment, extractSyntax): \n",
    "        \n",
    "    request = nlp_service.documents().annotateText(body={\n",
    "                \"document\":{\n",
    "                    \"type\": \"PLAIN_TEXT\",\n",
    "                    \"content\": text\n",
    "                    },\n",
    "                \"features\": {\n",
    "                    \"extractDocumentSentiment\": extractDocumentSentiment,\n",
    "                    \"extractEntities\": extractEntities,\n",
    "                    \"extractEntitySentiment\": extractEntitySentiment, # only available in v1beta2\n",
    "                    \"extractSyntax\": extractSyntax,\n",
    "                    },\n",
    "                \"encodingType\":\"UTF8\"\n",
    "                })\n",
    "    responses = request.execute(num_retries=3)        \n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ChatbotVS_nlp_generate_reply(responses):\n",
    "    nlp_reply = u' ---- I analyzed your text ----\\n ---- 嗯，我认真考虑了你的话 ----'\n",
    "    \n",
    "    # 1. 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "    nlp_reply += '\\n'\n",
    "    nlp_reply += '\\n' + u'[  Whole text 全文 Lang 语种 : {} ]\\n( 褒贬程度 : {} | 语彩累积 : {} )'.format(\n",
    "            responses['language']\n",
    "            , responses['documentSentiment']['score']\n",
    "            , responses['documentSentiment']['magnitude']\n",
    "        )\n",
    "\n",
    "    # 2. 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)           \n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['sentences'])):\n",
    "        nlp_reply += '\\n' + u'[ Phrase 语句 {} : {} ]\\n( 褒贬程度 : {} | 语彩累积 : {} )'.format(\n",
    "              i+1\n",
    "            , responses['sentences'][i]['text']['content']\n",
    "            , responses['sentences'][i]['sentiment']['score']\n",
    "            , responses['sentences'][i]['sentiment']['magnitude']\n",
    "        )\n",
    "                \n",
    "    # 3. 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['entities'])): \n",
    "        nlp_reply += '\\n' + u'[ Entity 实体 {} : {} ]\\n  Category 类别 : {}\\n  Importance 重要程度 : {}'.format(\n",
    "              i+1\n",
    "            , responses['entities'][i]['name']\n",
    "            , responses['entities'][i]['type']\n",
    "            , responses['entities'][i]['salience']\n",
    "        )\n",
    "        if 'sentiment' in responses['entities'][i]:\n",
    "            nlp_reply += '\\n' + u'  褒贬程度 : {}\\n  语彩累积 : {}'.format(\n",
    "                  responses['entities'][i]['sentiment']['score']\n",
    "                , responses['entities'][i]['sentiment']['magnitude']\n",
    "            )\n",
    "        if responses['entities'][i]['metadata'] != {}:\n",
    "            if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "                nlp_reply += '\\n  ' + responses['entities'][i]['metadata']['wikipedia_url']\n",
    "                           \n",
    "    # 4. 语句的语法分析 (Syntax / Grammar analysis)\n",
    "#     nlp_reply += '\\n'\n",
    "#     for i in range(len(responses['tokens'])): \n",
    "#         nlp_reply += '\\n' + str(responses['tokens'][i])\n",
    "    \n",
    "    return nlp_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 如果收到[TEXT, MAP, CARD, NOTE, SHARING]类的信息，会自动回复：\n",
    "@itchat.msg_register([MAP, CARD, SHARING, RECORDING, ATTACHMENT, VIDEO]) # 位置、名片、分享、语音、文件、视频\n",
    "def text_reply(msg):\n",
    "    itchat.send(u'You sent me something strange, I will never open it!\\n你给我发的都是些啥啊，我保证我不会打开的!', msg['FromUserName'])\n",
    "\n",
    "# #如果收到新朋友的请求，会自动通过验证添加加好友，并主动打个招呼：幸会幸会！Nice to meet you!\n",
    "@itchat.msg_register(FRIENDS)\n",
    "def add_friend(msg):\n",
    "    itchat.add_friend(**msg['Text']) # 该操作会自动将新好友的消息录入，不需要重载通讯录\n",
    "    itchat.send_msg(u'Welcome to Chatbot of Vicious!\\n\\\n",
    "    I can chat with you using movie subtitles.\\n\\\n",
    "    Add a slash / to the beginning and I will translate it.\\n\\\n",
    "    Add a star to the beginning and I will analyze it.\\n\\\n",
    "    Send me a photo and I will identify it.\\n\\\n",
    "    Try to send me some text (English/Chinese) or a photo.\\n\\\n",
    "    欢迎来到Vicious的聊天机器人!\\n\\\n",
    "    我可以回复电影台词跟你对话\\n\\\n",
    "    句子开头加一个斜杠/我会帮你翻译\\n\\\n",
    "    句子开头加一个星号*我会帮你分析\\n\\\n",
    "    发给我一张图片我可以帮你识别\\n\\\n",
    "    给我一段文字(中/英文)或者一张图片试试吧！', msg['RecommendInfo']['UserName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @itchat.msg_register([PICTURE], isGroupChat=True)\n",
    "@itchat.msg_register([PICTURE])\n",
    "def download_files(msg):\n",
    "    parm_translation_origin_language = 'zh' # will be overwriten by TEXT_DETECTION\n",
    "    msg.download(msg.fileName)\n",
    "#     print('\\nDownloaded image file name is: %s' % msg['FileName'])\n",
    "    image_base64 = encode_image(msg['FileName'])\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    #                                          call image analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    image_analysis_reply = u'---- Your image is interesting ----\\n---- 哟，你的图片好有意思 ----\\n'\n",
    "\n",
    "    # 1. LABEL_DETECTION:\n",
    "    LABEL_DETECTION = ChatbotVS_LABEL_DETECTION(image_base64, 'LABEL_DETECTION', parm_image_maxResults)\n",
    "    if LABEL_DETECTION != (u'\\nDid you send me\\n你给我发的是' + u'[ Nill 无结果 ]\\n'):\n",
    "        image_analysis_reply += LABEL_DETECTION\n",
    "    # 2. LANDMARK_DETECTION:\n",
    "    LANDMARK_DETECTION = ChatbotVS_LANDMARK_DETECTION(image_base64, 'LANDMARK_DETECTION', parm_image_maxResults)\n",
    "    if LANDMARK_DETECTION != (u'\\nThis place is\\n这个地方貌似是' + u'[ Nill 无结果 ]\\n'):\n",
    "        image_analysis_reply += LANDMARK_DETECTION\n",
    "    # 3. LOGO_DETECTION:\n",
    "    LOGO_DETECTION = ChatbotVS_LOGO_DETECTION(image_base64, 'LOGO_DETECTION', parm_image_maxResults)\n",
    "    if LOGO_DETECTION != (u'\\nThis mark is\\n这个商标好像是' + u'[ Nill 无结果 ]\\n'):\n",
    "        image_analysis_reply += LOGO_DETECTION\n",
    "    # 4. TEXT_DETECTION:\n",
    "    TEXT_DETECTION = ChatbotVS_TEXT_DETECTION(image_base64, 'TEXT_DETECTION', parm_image_maxResults)\n",
    "    if TEXT_DETECTION != (u'\\nI found text\\n我找到文字: ' + u'[ Nill 无结果 ]\\n'):\n",
    "        image_analysis_reply += TEXT_DETECTION\n",
    "    # 5. FACE_DETECTION:\n",
    "    FACE_DETECTION = ChatbotVS_FACE_DETECTION(image_base64, 'FACE_DETECTION', parm_image_maxResults)\n",
    "    if FACE_DETECTION != (u'\\nI found your emotions\\n你们的表情被我发现了:\\n'):\n",
    "        image_analysis_reply += FACE_DETECTION\n",
    "    # 6. SAFE_SEARCH_DETECTION:\n",
    "    SAFE_SEARCH_DETECTION = ChatbotVS_SAFE_SEARCH_DETECTION(image_base64, 'SAFE_SEARCH_DETECTION', parm_image_maxResults)\n",
    "    if SAFE_SEARCH_DETECTION != (u'\\nI also detected some bad content\\n我还检测到不良内容:\\n'):\n",
    "        image_analysis_reply += SAFE_SEARCH_DETECTION\n",
    "    \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果收到[TEXT]类的信息，会自动回复：\n",
    "@itchat.msg_register([TEXT]) # 文字\n",
    "def text_reply(msg):\n",
    "    # Translate recognised text to another language:\n",
    "    parm_translation_origin_language = ''\n",
    "    parm_translation_target_language = 'en'\n",
    "    translated_text_reply = ''\n",
    "    nlp_reply = ''\n",
    "    res_reply = ''\n",
    "    \n",
    "    if msg['Text'][0] == ('/'):\n",
    "        temp_translated_text_reply = msg['Text'][1:]\n",
    "        translated_text_reply = ChatbotVS_TEXT_TRANSLATION(temp_translated_text_reply, \n",
    "                                                       parm_translation_origin_language, parm_translation_target_language)\n",
    "    ##############################################################################################################\n",
    "    # call NLP API:\n",
    "    elif msg['Text'][0] == ('*'):\n",
    "        text4nlp = msg['Content'][1:]\n",
    "        nlp_responses = ChatbotVS_nlp(text4nlp\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n",
    "        # Format NLP results:\n",
    "        nlp_reply = ChatbotVS_nlp_generate_reply(nlp_responses)\n",
    "    ##############################################################################################################\n",
    "    # chat using corpus:\n",
    "    else :\n",
    "        res_reply = str(chatbot.get_response(msg['Content']))\n",
    "\n",
    "    return translated_text_reply + nlp_reply + res_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start auto replying.\n"
     ]
    }
   ],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # 安全退出"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
